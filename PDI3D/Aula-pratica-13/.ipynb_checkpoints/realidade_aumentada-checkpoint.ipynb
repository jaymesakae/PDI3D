{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7d8372d",
   "metadata": {},
   "source": [
    "Na aula de hoje veremos o conceito de realidade aumentada e suas aplicações\n",
    "\n",
    "Podemos tambem chamar esse conceito de modelo de cameras, pois veremos e analisaremos como uma camera funciona, então veremos alguns conceitos para identificar a distancia focal de uma camera e seus tipos de lentes\n",
    "\n",
    "Apresentaremos os conceitos agora:\n",
    "\n",
    "1. Lente esferica\n",
    "    \n",
    "    A lente esferica é a mesma ideia ja conhecida de tempos anteriores chamado de lente esferica, ou seja, uma imagem refletida sobre uma lente, terá um ponto focal que os unes, o mesmo chamado de eixo otico a linha que gera o ponto focal da camera, em outras palavras, o ponto que une todas as informações da imagem, a distancia da lente para um ponto é chamado de distancia focal\n",
    "    \n",
    "2. Plano focal\n",
    "    \n",
    "    É a ideia da distancia focal da lente e um plano que receberá os pixeis de intensidade dado pela iimagem tirada, assim, esse plano sera um plano atras da lente para receber os pixeis, se for mais perto ou mais longe da lente, ele causará uma imagem borrada, pois os pixeis de intensidade serao divididos em varios pixeis armazenados, assim, mesclando objetos.\n",
    "    \n",
    "3. Captura da imegm de um objeto\n",
    "\n",
    "    Como capturamos uma imagem então? Para capturar uma  imagem, nós basicamente armazenamos os feixes de luzes passados pelo objeto\n",
    "    \n",
    "    A ideia de camea pinhole se mantem aqui, basicamente, se o buraco de uma camera pinhole for maior, ele deixara a imagem mais borrada, pois um ponto (um feixe de luz) será maior, assim, o mesmo pixel de valor de intensidade será distribuido para mais pixeis doq ele realmente é, assim, ficaraá borrado. Se usarmos uma lente junto com essa camera, a imagem recebera mais feixes de luz com maior nitides e assim, o sensor capturará uma imagem de melhor qualidade, mas se deixarmos o plano focal mais longe, a camerá receberá uma imagem borrada pelo mesmo motivo do pinhole.\n",
    "    \n",
    "    \n",
    "Em geral, a distancia focal de uma camera para o plano focal é diferente em X e Y, portanto:\n",
    "\n",
    "xi = fx * $\\frac {xc}{zc}$\n",
    "\n",
    "yi = fy * $\\frac {yc}{zc}$\n",
    "\n",
    "Sendo f a distancia focal da lente para o plano focal.\n",
    "\n",
    "Transformando isso em coordenadas homogenias, teremos:\n",
    "\n",
    "[xi] = [fx 0 0] * [xc]\n",
    "\n",
    "[yi] = [0 fy 0] * [yc]\n",
    "\n",
    "[N] = [0 0 1] * [zc]\n",
    "\n",
    "Onde N ali não existe, só deixei ali pra n ficar feio na hora de fazer a demonstração (tenho mt a aprender de markdown ainda kkkkk)\n",
    "\n",
    "Temos que deixar essa matrix acima mais geral, pois ela ainda está mt confusa e não aborda todoos os pontos que queremos ressaltar\n",
    "\n",
    "[xi] = [fx 0 cx] * [xc]\n",
    "\n",
    "[yi] = [0 fy cy] * [yc]\n",
    "\n",
    "[N] = [0 0 1] * [zc]\n",
    "\n",
    "Novamente, esse N ai n existe\n",
    "\n",
    "A segunda matriz é chamada de matriz intríseca da camera\n",
    "\n",
    "A estimativa de pose de um objeto é as coordenadas de um objeto capturado pela camera, assim, sendo os pontos (xo->, yo->, zo->). A estimativa de pose é basicamente fazer a rotação e a translação do objeto em relação a camera, assim, conseguimos fazer a identificação de todos os pontos do objeto e melhor visualização do objeto\n",
    "\n",
    "As coordenadas (xo, yo, zo) e (xc, yc, zc) estão relacionados por uma translação + rotação\n",
    "\n",
    "Podemos então escrever a rotação do objeto para a camera:\n",
    "\n",
    "rc-> =\n",
    "\n",
    "[r1 r2 r3 tx] * ro->\n",
    "\n",
    "[r4 r5 r6 ty]\n",
    "\n",
    "[r7 r8 r9 tz]\n",
    "\n",
    "A matrix intriseca chamaremos de Mi e extrisica Me\n",
    "\n",
    "a matrix acima é igual a \n",
    "\n",
    "Me * ro->\n",
    "\n",
    "\n",
    "Resumindo\n",
    "\n",
    "ri-> = Mi * Me * ro->\n",
    "\n",
    "ri é os pixeis da imagem, Mi a matriz intriseca, Me a matrix extrinsica e ro-> o vetor do objeto\n",
    "\n",
    "Portanto, podemos mapear qualquer ponto na coordenada do objeto no pixel correspondente\n",
    "\n",
    "Dado um conjunto de pontos do objeto ro-> e ri-> (as posições do objeto na imagem), minimizamos :\n",
    "\n",
    "S = $\\sum_{j=1}^{N} (ri-> - Mi*Me*ro->)²$\n",
    "\n",
    "isso, em outras palavras é o erro quadratico da diferença da distancia do objeto para o centro da imagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6843cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2928c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_corners(data_dir, grid_size):\n",
    "    files = os.listdir(data_dir)\n",
    "    criteria = (cv2.TERM_CRITERIA_MAX_ITER + cv2.TERM_CRITERIA_EPS, 30, 0.1)\n",
    "    img_points = []\n",
    "    for fname in files:\n",
    "        img = cv2.imread(str(data_dir/fname))\n",
    "        img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        ret, corners = cv2.findChessboardCorners(img_gray, grid_size)\n",
    "        \n",
    "        if ret == True:\n",
    "            corners_sub = cv2.cornerSubPix(img_gray, corners, (11, 11), (-1, -1), criteria)\n",
    "            img_points.append(corners_sub)\n",
    "        else:\n",
    "            print('Pontos não detectados na imagem:', fname)\n",
    "    return img_points\n",
    "\n",
    "def check_corners_detection(data_dir, grid_size, img_points):\n",
    "    files = os.listdir(data_dir)\n",
    "    for fname, corners in zip(files, img_points):\n",
    "        img = cv2.imread(str(data_dir/fname))\n",
    "        cv2.drawChessboardCorners(img, grid_size, corners, True)\n",
    "        \n",
    "        cv2.imshow('img', img)\n",
    "        cv2.waitKey(0)\n",
    "    \n",
    "    cv2.destroyAllWindows()\n",
    "    cv2.waitKey(1)\n",
    "    \n",
    "    return\n",
    "        \n",
    "grid_size = (7, 6)\n",
    "dir_img = Path('../board')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "638eafc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_points = detect_corners(dir_img, grid_size)\n",
    "check_corners_detection(dir_img, grid_size, img_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "404f3f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.49704831e+03 0.00000000e+00 9.05467318e+02]\n",
      " [0.00000000e+00 1.54857470e+03 4.97768942e+02]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00]]\n",
      "fx = 1497.048313452922, fy = 1548.574703950075, cx = 905.4673181973168, cy = 497.76894215427814\n"
     ]
    }
   ],
   "source": [
    "def chessboard_grid_points(grid_size):\n",
    "    obj_points = np.zeros((grid_size[0]*grid_size[1], 3), dtype = np.float32)\n",
    "    obj_points[:, 0:2] = np.mgrid[0:grid_size[0], 0:grid_size[1]].transpose().reshape(-1, 2)\n",
    "    \n",
    "    return obj_points\n",
    "\n",
    "def calibrate(obj_points, img_points, img_size):\n",
    "    flags = cv2.CALIB_ZERO_TANGENT_DIST + cv2.CALIB_FIX_K1 +\\\n",
    "    cv2.CALIB_FIX_K2 + cv2.CALIB_FIX_K3\n",
    "    \n",
    "    error, mat_int, dist, rvecs, tvects =cv2.calibrateCamera(obj_points, img_points, img_size, \n",
    "                        cameraMatrix = None, distCoeffs = None, flags = flags)\n",
    "    \n",
    "    return mat_int, error\n",
    "\n",
    "img = cv2.imread(str(dir_img/'imagem1.jpg'))\n",
    "obj_p = chessboard_grid_points(grid_size)\n",
    "obj_points = []\n",
    "for i in range(len(img_points)):\n",
    "    obj_points.append(obj_p)\n",
    "    \n",
    "mat_int, error = calibrate(obj_points, img_points, img.shape[:-1][::-1])\n",
    "print(mat_int)\n",
    "print(f'fx = {mat_int[0,0]}, fy = {mat_int[1,1]}, cx = {mat_int[0,2]}, cy = {mat_int[1,2]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e99b7b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawn_axes(img, proj_points):\n",
    "        img = cv2.line(img, pt1 = proj_points[0], pt2 = proj_points[1], \n",
    "                       color = (255, 0, 0), thickness = 5)\n",
    "        img = cv2.line(img, pt1 = proj_points[0], pt2 = proj_points[2], \n",
    "                       color = (0, 255, 0), thickness = 5)\n",
    "        img = cv2.line(img, pt1 = proj_points[0], pt2 = proj_points[3], \n",
    "                       color = (0, 0, 255), thickness = 5)\n",
    "        return img\n",
    "\n",
    "def drawn_axes_on_img(data_dir, mat_int, obj_points, img_points):\n",
    "    axes = np.array([[0,0,0], \n",
    "                     [3, 0, 0],\n",
    "                     [0, 3, 0],\n",
    "                     [0, 0, -3]], np.float32)\n",
    "    \n",
    "    files = os.listdir(data_dir)\n",
    "    for idx, fname in enumerate(files):\n",
    "        img = cv2.imread(str(data_dir/fname))\n",
    "        ret, rvec, tvec = cv2.solvePnP(obj_points[idx], img_points[idx], mat_int, None)\n",
    "        if ret == True:\n",
    "            proj_points, _ = cv2.projectPoints(axes, rvec, tvec, mat_int, None)\n",
    "            \n",
    "            #arredondando e removendo uma dimensão inutil\n",
    "            proj_points = np.round(proj_points).astype(int).squeeze()\n",
    "            \n",
    "            img = drawn_axes(img, proj_points)\n",
    "            cv2.imshow('img', img)\n",
    "            cv2.waitKey(0)\n",
    "        else:\n",
    "            print(f'nao foi possivel estimar para a imagem {img}')\n",
    "            \n",
    "    cv2.destroyAllWindows()\n",
    "    cv2.waitKey(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "509efcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "drawn_axes_on_img(dir_img, mat_int, obj_points, img_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f424352",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
